---
title: CUMCM 2024 Summary
weight: 20
draft: false
description: The summary of the CUMCM 2024
slug: cumcm2024
tags:
  - math
  - CUMCM
series:
  - MathModel
series_order: 2
date: 2024-09-12
authors:
  - Morethan
---

## Reference
Honestly, I'm not familiar with BayesianOPT, the opinions mentioned stem from the below. ğŸ‘‡

- [ã€æœºå™¨å­¦ä¹ ã€‘ä¸€æ–‡çœ‹æ‡‚è´å¶æ–¯ä¼˜åŒ–/Bayesian Optimization](https://blog.csdn.net/qq_27590277/article/details/115451660)

- [ä¸€æ–‡è¯¦è§£è´å¶æ–¯ä¼˜åŒ–ï¼ˆBayesian Optimizationï¼‰åŸç†](https://www.cnblogs.com/milliele/p/17782631.html)

- [è´å¶æ–¯ä¼˜åŒ–(BayesianOptimization)](https://blog.csdn.net/Leon_winter/article/details/86604553)

- [è¶…å‚æ•°ä¼˜---è´å¶æ–¯ä¼˜åŒ–åŠå…¶æ”¹è¿›ï¼ˆPBTä¼˜åŒ–ï¼‰](https://blog.csdn.net/xys430381_1/article/details/103871212)

- [è´å¶æ–¯ä¼˜åŒ– (Bayesian Optimization)](https://leovan.me/cn/2020/06/bayesian-optimization/)

- [MATLAB Offical Document](https://ww2.mathworks.cn/help/stats/bayesopt.html?s_tid=srchtitle_site_search_1_bayesopt)


## Advantages & Algorithm Principle
Here we are going to talk about the advantages & algorithm principle of BayesianOPT. If you only want to konw how to use it, you can read the `#Advantage` section, then go to the [#MATLAB Practice]({{<relref "#matlab-practice">}})

### Advantages

### Algorithm Principle

## MATLAB Practice
Well, we can put Bayesian Optimization into practice even though we don't understand it, using the predefined function of MATLAB, the 'bayesopt'. Here is the official guidance of the function: [bayesopt](https://ww2.mathworks.cn/help/stats/bayesopt.html?s_tid=srchtitle_site_search_1_bayesopt)

### Final code display
```matlab
% define the obj function
function y = objectiveFcn(x)
    y = (1 - x.x1)^2 + 100 * (x.x2 - x.x1^2)^2;
end

% define the variables
vars = [optimizableVariable('x1', [-2, 2])
        optimizableVariable('x2', [-2, 2])];

% conduce the optimizer
results = bayesopt(@objectiveFcn, vars, ...
                   'AcquisitionFunctionName', 'expected-improvement-plus', ...
                   'MaxObjectiveEvaluations', 30, ...
                   'IsObjectiveDeterministic', true, ...
                   'Verbose', 1);

% get result
bestPoint = results.XAtMinObjective;
bestObjective = results.MinObjective;

% result output
fprintf('æœ€ä¼˜è§£ x1: %.4f, x2: %.4f\n', bestPoint.x1, bestPoint.x2);
fprintf('æœ€ä¼˜ç›®æ ‡å€¼: %.4f\n', bestObjective);
```

{{<alert>}}
I'd commit that the code is generated by AI ğŸ¥²

AI is a better coder, at least when comparing with me. ğŸ« 
{{</alert>}}

### Parameters Explaination

| Params                     | Meaning                                                                                                    |
| -------------------------- | ---------------------------------------------------------------------------------------------------------- |
| `AcquisitionFunctionName`  | select a Acquisition Function, which Â determines the method how bayesopt choose the next acquisition point |
| `MaxObjectiveEvaluations`  | the maximize evalu turns                                                                                   |
| `IsObjectiveDeterministic` | If the obj function contains noise, set to `true` ; Otherwise, set to `false`                              |
| `Verbose`                  | Determine the detailing extend of console output, the complete output includes many figures.               |

Want more detailed information? Refer to the Offical document: [bayesopt](https://ww2.mathworks.cn/help/stats/bayesopt.html?s_tid=srchtitle_site_search_1_bayesopt). It's more completed and with amount of examples.

{{<alert>}}
It's basic for every MathModeler to read the offical document. ğŸ˜
{{</alert>}}
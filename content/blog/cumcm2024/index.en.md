---
title: CUMCM 2024 Summary
weight: 20
draft: false
description: The summary of the CUMCM 2024
slug: cumcm2024
tags:
  - math
  - CUMCM
series:
  - MathModel
series_order: 2
date: 2024-09-12
authors:
  - Morethan
---

## Reference
Honestly, I'm not familiar with BayesianOPT, the opinions mentioned stem from the below. 👇

- [【机器学习】一文看懂贝叶斯优化/Bayesian Optimization](https://blog.csdn.net/qq_27590277/article/details/115451660)

- [一文详解贝叶斯优化（Bayesian Optimization）原理](https://www.cnblogs.com/milliele/p/17782631.html)

- [贝叶斯优化(BayesianOptimization)](https://blog.csdn.net/Leon_winter/article/details/86604553)

- [超参数优---贝叶斯优化及其改进（PBT优化）](https://blog.csdn.net/xys430381_1/article/details/103871212)

- [贝叶斯优化 (Bayesian Optimization)](https://leovan.me/cn/2020/06/bayesian-optimization/)

- [MATLAB Offical Document](https://ww2.mathworks.cn/help/stats/bayesopt.html?s_tid=srchtitle_site_search_1_bayesopt)


## Advantages & Algorithm Principle
Here we are going to talk about the advantages & algorithm principle of BayesianOPT. If you only want to konw how to use it, you can read the `#Advantage` section, then go to the [#MATLAB Practice]({{<relref "#matlab-practice">}})

### Advantages

### Algorithm Principle

## MATLAB Practice
Well, we can put Bayesian Optimization into practice even though we don't understand it, using the predefined function of MATLAB, the 'bayesopt'. Here is the official guidance of the function: [bayesopt](https://ww2.mathworks.cn/help/stats/bayesopt.html?s_tid=srchtitle_site_search_1_bayesopt)

### Final code display
```matlab
% define the obj function
function y = objectiveFcn(x)
    y = (1 - x.x1)^2 + 100 * (x.x2 - x.x1^2)^2;
end

% define the variables
vars = [optimizableVariable('x1', [-2, 2])
        optimizableVariable('x2', [-2, 2])];

% conduce the optimizer
results = bayesopt(@objectiveFcn, vars, ...
                   'AcquisitionFunctionName', 'expected-improvement-plus', ...
                   'MaxObjectiveEvaluations', 30, ...
                   'IsObjectiveDeterministic', true, ...
                   'Verbose', 1);

% get result
bestPoint = results.XAtMinObjective;
bestObjective = results.MinObjective;

% result output
fprintf('最优解 x1: %.4f, x2: %.4f\n', bestPoint.x1, bestPoint.x2);
fprintf('最优目标值: %.4f\n', bestObjective);
```

{{<alert>}}
I'd commit that the code is generated by AI 🥲

AI is a better coder, at least when comparing with me. 🫠
{{</alert>}}

### Parameters Explaination

| Params                     | Meaning                                                                                                    |
| -------------------------- | ---------------------------------------------------------------------------------------------------------- |
| `AcquisitionFunctionName`  | select a Acquisition Function, which  determines the method how bayesopt choose the next acquisition point |
| `MaxObjectiveEvaluations`  | the maximize evalu turns                                                                                   |
| `IsObjectiveDeterministic` | If the obj function contains noise, set to `true` ; Otherwise, set to `false`                              |
| `Verbose`                  | Determine the detailing extend of console output, the complete output includes many figures.               |

Want more detailed information? Refer to the Offical document: [bayesopt](https://ww2.mathworks.cn/help/stats/bayesopt.html?s_tid=srchtitle_site_search_1_bayesopt). It's more completed and with amount of examples.

{{<alert>}}
It's basic for every MathModeler to read the offical document. 😝
{{</alert>}}
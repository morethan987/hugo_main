---
title: Notes on the Foundation of Large Models
weight: -110
draft: true
description: Notes written after reading the textbook "Foundation of Large Models" from Zhejiang University
slug: llm-foundation-notes
tags:
  - LLM
  - EngineeringPractice
  - Notes
series:
  - AI Engineering
series_order: 2
date: 2025-05-28
lastmod: 2025-05-28
authors:
  - Morethan
---
{{< lead >}}
Notes written after reading the textbook "Foundation of Large Models" from Zhejiang University
{{< /lead >}}

## Preface

The development of large model technology can be described as "rapidly evolving," with seemingly groundbreaking advancements happening every day. ü§î

In reality, how effective are these "groundbreaking advancements"? What is their actual value in engineering practice? Ultimately, these questions must be traced back to those "ordinary" classic principles.

It's certainly a good thing to keep up with the latest developments in large model technology: it helps us understand research directions and broaden our thinking. However, we should not only focus on the ever-evolving top-tier technologies but also pay attention to the underlying, unchanging fundamentals behind them.

This is the significance of taking the time to read textbooks in an era of rapid technological advancement.

This article primarily focuses on the book [‚ÄúFoundation of Large Models‚Äù](https://github.com/ZJU-LLMs/Foundations-of-LLMs) written by Zhejiang University, which is still being continuously updated.

## Basics of Language Models

## Architecture of Large Language Models

## Parameter-Efficient Fine-Tuning

## Model Editing


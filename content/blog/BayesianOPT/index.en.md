---
title: Bayesian Optimization
weight: -10
draft: false
description: BayesianOPT principle and its MATLAB implementation
slug: bayesianopt
tags:
  - math
  - MATLAB
  - CUMCM
series:
  - MathModel
series_order: 1
date: 2024-08-05
lastmod: 2024-12-20
authors:
  - Morethan
---

## Reference
Honestly, I'm not familiar with BayesianOPT, the opinions mentioned stem from the below. ğŸ‘‡

- [ã€æœºå™¨å­¦ä¹ ã€‘ä¸€æ–‡çœ‹æ‡‚è´å¶æ–¯ä¼˜åŒ–/Bayesian Optimization](https://blog.csdn.net/qq_27590277/article/details/115451660)

- [ä¸€æ–‡è¯¦è§£è´å¶æ–¯ä¼˜åŒ–ï¼ˆBayesian Optimizationï¼‰åŸç†](https://www.cnblogs.com/milliele/p/17782631.html)

- [è´å¶æ–¯ä¼˜åŒ–(BayesianOptimization)](https://blog.csdn.net/Leon_winter/article/details/86604553)

- [è¶…å‚æ•°ä¼˜---è´å¶æ–¯ä¼˜åŒ–åŠå…¶æ”¹è¿›ï¼ˆPBTä¼˜åŒ–ï¼‰](https://blog.csdn.net/xys430381_1/article/details/103871212)

- [è´å¶æ–¯ä¼˜åŒ– (Bayesian Optimization)](https://leovan.me/cn/2020/06/bayesian-optimization/)

- [MATLAB Offical Document](https://ww2.mathworks.cn/help/stats/bayesopt.html?s_tid=srchtitle_site_search_1_bayesopt)


## Advantages & Algorithm Principle
Here we are going to talk about the advantages & algorithm principle of BayesianOPT. If you only want to konw how to use it, you can read the `#Advantage` section, then go to the [ MATLAB Practice]({{< relref "#matlab-practice" >}})

### Advantages

### Algorithm Principle

## MATLAB Practice
Well, we can put Bayesian Optimization into practice even though we don't understand it, using the predefined function of MATLAB, the `bayesopt`. Here is the official guidance of the function: [bayesopt](https://ww2.mathworks.cn/help/stats/bayesopt.html?s_tid=srchtitle_site_search_1_bayesopt)

### Final code display
```matlab
% define the obj function
function y = objectiveFcn(x)
    y = (1 - x.x1)^2 + 100 * (x.x2 - x.x1^2)^2;
end

% define the variables
vars = [optimizableVariable('x1', [-2, 2])
        optimizableVariable('x2', [-2, 2])];

% conduce the optimizer
results = bayesopt(@objectiveFcn, vars, ...
                   'AcquisitionFunctionName', 'expected-improvement-plus', ...
                   'MaxObjectiveEvaluations', 30, ...
                   'IsObjectiveDeterministic', true, ...
                   'Verbose', 1);

% get result
bestPoint = results.XAtMinObjective;
bestObjective = results.MinObjective;

% result output
fprintf('æœ€ä¼˜è§£ x1: %.4f, x2: %.4f\n', bestPoint.x1, bestPoint.x2);
fprintf('æœ€ä¼˜ç›®æ ‡å€¼: %.4f\n', bestObjective);
```


{{< alert icon="pencil" cardColor="#1E3A8A" textColor="#E0E7FF" >}}
I'd commit that the code is generated by AI. ğŸ¥² AI is a better coder, at least when comparing with me. ğŸ« 
{{< /alert >}}

### Parameters Explaination

| Params                     | Meaning                                                                                                    |
| -------------------------- | ---------------------------------------------------------------------------------------------------------- |
| `AcquisitionFunctionName`  | select a Acquisition Function, which Â determines the method how bayesopt choose the next acquisition point |
| `MaxObjectiveEvaluations`  | the maximize evalu turns                                                                                   |
| `IsObjectiveDeterministic` | If the obj function contains noise, set to `true` ; Otherwise, set to `false`                              |
| `Verbose`                  | Determine the detailing extend of console output, the complete output includes many figures.               |

Want more detailed information? Refer to the Offical document: [bayesopt](https://ww2.mathworks.cn/help/stats/bayesopt.html?s_tid=srchtitle_site_search_1_bayesopt). It's more completed and with amount of examples.


{{< alert icon="pencil" cardColor="#1E3A8A" textColor="#E0E7FF" >}}
It's basic for every MathModeler to read the offical document. ğŸ˜
{{< /alert >}}
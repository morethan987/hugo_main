---
title: CTM读文笔记
weight: -105
draft: true
description: 一个新型的人脑启发式AI架构
slug: ctm-note
tags:
  - 论文
  - 笔记
  - 架构
series:
  - 论文笔记
series_order: 2
date: 2025-05-14
lastmod: 2025-05-19
authors:
  - Morethan
---
{{< lead >}}
一个新型的人脑启发式架构，在现有时序无关的神经元模型的基础上引入了"时序"概念，涌现出一系列类似人脑的现象
{{< /lead >}}

## 前言

关注到这篇论文其实就是因为其宣称的那种"奇妙"的涌现现象，将时序信息引入神经元模型之后产生了**类似人类思维模式**的注意力现象。这些现象并非人为设计的，而是在训练过程中自然产生的，这是最令人振奋的。

最直观的例子就是官方给出的"迷宫模型"，从可视化的结果可以直观地看到，模型的注意力焦点在迷宫中游走，就像人类求解迷宫问题一样。另外官方还给出了一个可交互的展示网页：[Demo](https://pub.sakana.ai/ctm/)，在这个网页中你可以直接指挥模型求解迷宫，并实时查看模型的注意力焦点。

另外，官方的[代码仓库](https://github.com/SakanaAI/continuous-thought-machines)中配置了详尽的说明文档和代码注释，代码文件的切分也非常简洁直观，有一种程序员才懂的"艺术感"。


{{< alert icon="pencil" cardColor="#1E3A8A" textColor="#E0E7FF" >}}
在阅读了大量的屎山代码之后，可能才会对代码的"优雅"程度有所体会😇并深刻理解这份"优雅"背后的工作量
{{< /alert >}}

## 引入

神经网络最初受生物大脑启发，却与生物大脑差异巨大。生物大脑展现出随时间演变的复杂神经动力学过程，而现代神经网络为了便于大规模深度学习，可以摒弃了"时序"特征。

关于为什么要开展这项研究，官方论文中已经有了非常明确的表述，无需多言：

"为何开展此项研究？诚然，现代人工智能在诸多实践领域展现出的卓越性能似乎表明，对神经动力学的模拟实无必要，抑或显式考量智能的时间维度实属反实用之举。然而，人类智能具有高度灵活性、数据高效性以及优异的未见情境外推能力，且存在于学习与适应皆与时间之箭紧密关联的开放世界中。因此，人类智能天然具备常识运用、本体论推理能力、透明性/可解释性以及强大的泛化能力——这些特质在现有人工智能中尚未得到令人信服的体现。"

这篇文章的核心技术贡献如下所示：

1. 解耦的内部时间维度
2. 神经元层面的模型(NLMs)
3. 神经活动同步

当然，在没有详细看代码实现的情况下，光看这些名词是没有意义的。但是作者的思路和观点还是可以了解：

1. 推理模型和循环：作者锐评了当前推理模型，指出"继续扩展当前模型架构"这条技术路线已经被很多研究质疑。而使用循环技术也的确能够让现有模型架构产生更加良好的表现，但是作者认为，**循环机制很重要，但是被循环机制解锁的神经元活动之间的精确时序与交互同样重要**
2. 有趣的副作用：CTM 内部的循环类似于人类的思考，在没有任何显式的监督函数引导的情况下就能够**为不同难度的任务自动分配合适的计算资源**，简单的任务将会提前终止计算，而复杂的任务将会进行更加深入的计算
3. **信息可以被编码在时序动态中**，这将赋予网络更加强大的信息压缩能力


{{< alert icon="pencil" cardColor="#1E3A8A" textColor="#E0E7FF" >}}
说明一下我对第三点的思考，按照"压缩即智能"的观点，将将信息编码到时序动态中将极大地提高网络的信息"压缩率"，从某种程度上来说也就提升了"智能"
{{< /alert >}}

最后作者也明确了自己这个研究的目的所在：

"通过CTM显式建模神经时序机制，我们旨在为开发更具生物合理性且高性能的人工智能系统开辟新路径。"

## 方法

![CTM.png](img/CTM.png)

